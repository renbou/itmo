\documentclass[times]{itmo-student-thesis}

%% Список источников в отдельном файле.
\usepackage{filecontents}
\begin{filecontents}{bachelor-thesis.bib}
@book{ bellman,
    author      = {R. E. Bellman},
    title       = {Dynamic Programming},
    address     = {Princeton, NJ},
    publisher   = {Princeton University Press},
    numpages    = {342},
    pagetotal   = {342},
    year        = {1957},
    langid      = {english}
}
\end{filecontents}
\addbibresource{bachelor-thesis.bib}

\begin{document}

%% \publishyear нужен для \printmainbibliography, которая далее выводит список источников по годам. 
\publishyear{2024}
%% \maketitle отредактирован, чтобы не выводить титульный лист и остальные страницы, т.к. они сейчас не нужны.
\maketitle{Бакалавр}

%%%%
%% Оглавление
%%%%
\tableofcontents

%%%%
%% Введение
%%%%
\startprefacepage

Разработка многих видов промышленного программного обеспечения (ПО) требует построения систем, распределенных по различным узлам исполнения,
которые могут быть представлены как отдельными серверами, расположенными в одном или нескольких датацентрах, так и виртуальными машинами, изолированными в пределах одного сервера,
или даже контейнерами, запускающимися на различного рода средах исполнения, таких как Docker или Kubernetes.
Распределенные системы применяются при разработке ПО, например, для улучшения таких качеств, как масштабируемость и отказоустойчивость,
что безусловно важно для ПО множества компаний с постоянно растущими объемами обрабатываемых данных,
а также для разбиения ПО на более гранулярные компоненты, что в свою очередь упрощает разработку и всей системы в целом.
Такой подход к проектированию ПО часто называется «микросервисной архитектурой», и особенно популярен среди крупных компаний,
одновременно занимающихся разработкой ПО совершенно разной направленности, например: Яндекс Еда и Яндекс Директ, интернет-магазин Озон и Озон Путешествия, Тинькофф Банк и Тинькофф Инвестиции. 

Абстрагируясь от архитектуры какой-либо конкретной распределенной системы, общепринятым способом построения связи в ПО, расположенным на различных узлах исполнения,
становятся сетевые вызовы, исполняющиеся в большинстве своем с использованием протоколов TCP или UDP, которые четко стандартизованы и позволяют устанавливать связь между
узлами исполнения независимо от конфигурации их вычислительных характеристик и используемых операционных систем, систем виртуализации или контейнеризации, и других подобных отличий.
Однако, сами TCP и UDP зачастую являются протоколами чересчур низкого уровня для разработчиков, так как предоставляют интерфейсы потоковой и блочной передачи данных
без дополнительного разделения на пакеты, без поддержки сессий или другой группировки данных в рамках одного соединения, без встроенных возможностей передачи метаданных.
Несмотря на указанные минусы, эти протоколы предоставляют качественный фундамент, на основании которого строятся уже более специализированные и удобные протоколы.
В рамках этой работы, однако, нам подробно понадобится рассмотреть именно протокол HTTP в его различных версиях, в частности, HTTP/2.0.

Связывая вышесказанное, перейдем к рассмотрению главного фокуса данной работы — протокола gRPC. Протокол gRPC был разработан Google специально для решения проблем
связывания распределенных систем по сети, и выпущен в открытый доступ в 2015 году сразу с поддержкой множества популярных языков программирования:
C++, Java, Go, Node.js, Python, и других. gRPC основан на HTTP/2.0, который он использует для предоставления разработчикам унифицированного интерфейса со множеством возможностей,
наиболее важными из которых, на мой взгляд, являются:
\begin{enumerate}
    \item Исполнение обычных (унарных) вызовов, состоящих из одной пары запрос/ответ;
    \item Потоковой передачи данных, причем как однонаправленной со стороны клиента/сервера, так и двунаправленной,
          которые часто используются при построении распределенных систем, обрабатывающих изменения данных в режиме реального времени;
    \item Передача дополнительных метаданных в начале запросов и ответов, а также после их завершения,
          что наиболее полезно для предоставления обеим сторонам дополнительных аналитических данных, доступных только после исполнения запроса;
    \item Параллельная обработка запросов в рамках одного соединения, что позволяет эффективно утилизировать низкоуровневое соединение TCP,
          которое используется HTTP/2.0 в качестве транспортного слоя, благодаря разбиению запросов/ответов на небольшие пакеты;
    \item Динамическая отмена исполнения запросов в рамках одного соединения, что важно для минимизации напрасных трат ресурсов систем,
          без накладных расходов в виде долгого пересоздания всего соединения, как было бы при прямом использовании протокола TCP. 
\end{enumerate}

Помимо этой фундаментальной функциональности, реализованной в gRPC с помощью возможностей, которые предоставляет HTTP/2.0 на уровне протокола,
стандартные реализации gRPC для многих языков, как официальные, так и неофициальные, предоставляют стандартизованную поддержку указания крайнего срока исполнения запроса,
улучшая уже упомянутую функциональность отмены запросов, а также сжатие передаваемых данных, и популярные алгоритмы балансировки исполнения запросов на нескольких серверах, вместо одного.

Вместе с самим gRPC, Google в 2008 году ввёл стандарт сериализации данных с использованием строго-типизированных контрактов, Protocol Buffers (Protobuf),
в который с выпуском gRPC была встроена поддержка для него на уровне синтаксиса самих контрактов. Таким образом, API, предоставляемые сервисами в распределенных системах с использованием gRPC,
имеют четко объявленный контракт, использующийся клиентами и серверами для передачи сообщений, что решает многие проблемы,
возникающие при разовой реализации сериализации/десериализации запросов/ответов разработчиками, отличающейся для каждой системы.
Более того, поддержка генерации кода всеми стандартными реализациями gRPC и Protobuf на основании этих контрактов
позволяют упростить разработку взаимодействия сервисов как со стороны клиентов, так и со стороны серверов,
предоставляя разработчикам упрощенные интерфейсы на конкретном используемом ими языке программирования.

gRPC подходит практически для любых сценариев сетевого взаимодействия ПО: взаимодействие серверных программ, взаимодействие десктопного приложения (программы на персональном компьютере) с сервером,
исполнение запросов из мобильного приложения (программы на телефонах и планшетах). Во всех этих сценариях каждая сторона имеет доступ к управлению сетевым соединением TCP и HTTP/2.0 напрямую,
что, к сожалению, невозможно для веб-приложений, запускающихся в браузерной среде. Таким образом, все удобства, предоставляемые gRPC, становятся недоступными при разработке веб-приложений,
использующих серверы для получения и хранения каких-либо данных, что практически является обязательным требованием для реализации любых многопользовательских сервисов (например, интернет-магазин,
социальная сеть, файловое хранилище).

Вместо прямого доступа к транспортным протоколам, таким как TCP и UDP, или даже более высокоуровневым протоколам, в которые входит и протокол HTTP разных версий,
среда исполнения веб-приложений, то есть браузер, предоставляет доступ к упрощенным API, абстрагирующим детали нижележащего протокола: Fetch, EventSource, WebSocket, WebTransport.
Соответственно, для связывания клиента одного из этих API в веб-приложении с gRPC API на сервере, требуется между ними устанавливать дополнительное ПО, шлюз,
умеющий конвертировать сообщения одного протокола в другой. Конечно, уже существуют общедоступные решения, предоставляющие часть такой функциональности,
однако все они, фактически, предоставляют только возможность использования Fetch API для исполнения унарных вызовов по gRPC,
и частично-реализованную возможность использования Fetch API для потоковой передачи данных со стороны сервера с конвертацией данных из формата сериализации Protobuf в менее оптимальный формат JSON.
Имеющиеся решения не поддерживают полноценную двунаправленную потоковую передачу данных, что нужно в таких приложениях, как социальные сети, стриминговых сервисах типа Twitch,
и онлайн-инструментах для торговли на бирже, например Тинькофф Инвестиции, или потоковую передачу данных со стороны клиента, что полезно для передачи аналитических данных в потоке без задержки,
и совершенно не поддерживают другие API, доступные веб-приложениям, каждое из которых имеет свои плюсы и сценарии использования.

Из вышесказанного естественным образом и вытекает цель и новизна данной работы — разработка программного шлюза, поддерживающего использование всех указанных выше API со входящей стороны,
и gRPC — с исходящей, благодаря чему будет в общем случае решена проблема связывания самого разного клиентского ПО с gRPC API, предоставляемых серверами.
Наравне с этой глобальной целью стоят также и дополнительные цели, достижение которых позволит достичь наиболее удобного и функционально готового результата:
\begin{enumerate}
    \item Совместимость функциональности шлюза с текущими решениями, что позволит разработчикам начать пользоваться новым решением без необходимости в изменении всей имеющийся логики;
    \item Поддержка проксирования gRPC для возможности использования шлюза в качестве единого сервера, которым пользуются все клиенты одного gRPC API;
    \item Реализация дополнительных возможностей gRPC на уровне шлюза, таких как указание крайнего срока исполнения запроса, чтобы помимо основной функциональности предоставлять клиентам максимальный набор удобств, имеющийся при стандартном использовании gRPC;
    \item Использование стандартизованного API gRPC рефлексии для получения полных контрактов целевых серверов, в которые производится проксирование,
          что позволит разработчикам не реализовывать дополнительные механизмы синхронизации исходных файлов контрактов серверов для шлюза,
          что требуется всеми текущими решениями, делая их ещё менее удобными.
\end{enumerate} 

Резюмируя, в результате выполнения данной работы будет получено абсолютно ПО, не имеющее аналогичных существующих решений, которые бы могли полностью заменить его функциональность.
Разработанный программный шлюз будет выложен с исходным кодом и иными материалами в виде публичного репозитория на интернет-ресурсе GitHub по ссылке https://github.com/renbou/grpcbridge,
что позволит любым разработчикам пользоваться им для собственных нужд без дополнительной настройки синхронизации gRPC контрактов и другого сложного конфигурирования,
требующегося при использовании существующих решений. Предоставление удобного инструмента для разработчиков, использующих gRPC для сетевого взаимодействия между компонентами распределенных систем,
который позволит им использовать gRPC и для разработки любых клиентских приложений, включая десктопные, мобильные, и веб-приложения, без лишней накладной работы — в этом и заключается практическая значимость данной работы.

%%%%з
%% Первая глава
%%%%
\chapter{Обзор предметной области}

В данной главе будут подробно рассмотрены со всей необходимой спецификой и существующими проблемами клиентские интерфейсы для сетевого взаимодействия, доступные веб-приложениям, которые были указаны во введении работы (Fetch, EventSource, WebSocket, WebTransport),
и существующие решения, частично покрывающие ту функциональность, которая будет доступна в новом разработанном шлюзе. Для успешного выполнения работы будет приведено разбиение работы на различные задачи, суммарное выполнение которых позволит прийти к целям, поставленным по введении.
Дополнительно будут рассмотрены технологии, которые будут использоваться для выполнения задач работы, например API gRPC-рефлексии, механизмы отмены и установления сроков исполнения запросов в gRPC, и другая похожая функциональность, знание которой является необходимой для разработки шлюза.

%%%%
%% Заключение
%%%%
\startconclusionpage

В данном разделе размещается заключение.

\printmainbibliography

%% После этой команды chapter будет генерировать приложения, нумерованные русскими буквами.
%% \startappendices из старого стилевика будет делать то же самое
\appendix

\end{document}
